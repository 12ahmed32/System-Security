System Security :
we will focus on attacking techniques like Buffer overflow and how we can Fuzz and reverse engineer applications to find vulnerabilities
Finally , utilizing these vulnerabilities and how to exploit them to execute arbitrary code on the target machine




CPU , ISA , registers 
instructions are commands in binary but represented in hexadecimal format , for humans can't read hex format so assembly language is used to translate the machine code [Hex] into more readable language .  instruction set architecture is the set of instructions that programmer (or compiler) must understand and use to write a program correctly for that specific CPU and machine note that each CPU has its own instruction set architecture . ISA is what a programmer can see : memory , registers , instructions ,etc. it provides all the necessary information for who wants to write a program in that machine language : one of most common ISA  is the x86 instruction set originated from the Intel 8086 . The x86 acronym identifies 32-bit processors , while x64 (aka x86_64 or AMD64) identifies the 64-bit versions


the number of bits , 32 or 64 , refers to the width of the CPU registers  . Each CPU has its fixed set of registers that are accessed when required . you can think of registers as temporary variables used by the CPU to get and store data . almost all   registers are small portions  of memory in the CPU and server to store data temporarily , it is important to know that some of them have specific functions , while some others are sued for general data storage 


The CPU registers serve as small storage areas used to access data quickly.  In the x86 (32-bit) architecture there are 8 general-purpose registers: EAX, EBX, ECX, EDX, EDI, ESI, EBP, and ESP.  They can technically be used to store any data, though they were originally architected to perform specific tasks, and in many cases are still used that way today.  



EAX-The Acuumulator Register 
t’s called the accumulator register because it’s the primary register used for common calculations (such as ADD and SUB).  While other registers can be used for calculations, EAX has been given preferential status by assigning it more efficient, one-byte opcodes.  Such efficiency can be important when it comes to writing exploit shellcode for a limited available buffer space
in addition to its use in calculations , EAX is also used to store the return value of a function
This general purpose register can be referenced in whole or in part as follows: EAX refers to the 32-bit register in its entirety. AX refers to the least significant 16 bits which can be further broken down into AH (the 8 most significant bits of AX) and AL (the 8 least significant bits).
This same whole/partial 32-, 16-, and 8-bit referencing also applies to the next three registers (EBX, ECX, and EDX)
---------------
Importance in Exploitation:
Efficiency in Exploits: When writing exploit shellcode, the size of the payload is often restricted by the available buffer space. Using one-byte opcodes allows the shellcode to be more compact and efficient, fitting more instructions into the limited space. This is especially important when trying to execute a specific sequence of operations within a constrained memory area.
--------------------
Opcode: In machine language, an instruction is made up of two parts: the opcode, which specifies what operation to perform (e.g., ADD, SUB, MOV), and the operands, which specify the data or the memory locations the operation will use.
-----------------------
One-Byte Opcode: When an instruction is encoded in machine language, the opcode can vary in size. A one-byte opcode means that the entire operation code is contained within a single byte (8 bits). This is the smallest possible size for an opcode.
-----------------------
Registers like EAX are used to store data, not instructions. They hold values that the CPU uses during execution, such as intermediate results in calculations or memory addresses.

Instructions in machine code consist of an opcode (which specifies the operation) and operands (which specify the data or memory locations to be used). These instructions are stored in memory and fetched by the CPU to execute.
----------------------
SUMMARY
---------------------
so the instructions are stored in the memory can be 1 byte opcode or more bigger and the CPU fetches these instruction from the memory by the pointer register and when it fetch the instruction which consist of 2 parts operation which can be represented in 1 byte and operands which is values directly or addresses in memory storing these values and as the CPU executing these instruction it needs to store intermediate values so it uses registers for this and each register is used in specific operation like EAX in addition so this can be helpful when exploiting Buffer Over Flow as we want to inject shellcode (series of machine code) in limited size memory (buffer)
----------------------------------------------
EIP instruction pointer
controls the program execution by storing a pointer to the address of the next instruction
(machine code) that will be executed
it tells the CPU where the next instruction is
-----------------------------
stack frame keeps track of the location where control returns from procedures and calls


---------------------------------------

so when we call a function we push the arguments of this function from right to left which results in storing the first argument on the left to the lowest address then we call the function and here we should focus on EIP which is done pointing the call instruction as it executed by the cpu and now it points to the first instruction after the call instruction so we push this content to the stack which help us to determine the address to return the control after the function completes its execution and then after we saved the address to return we can jump to the address of the function and start its execution which needs adjusting the ESP as it needs increament or decreament of the stack storing or removing data then simply we return to the address which we start from 

---------------------------------------
1. Push Function Arguments onto the Stack:
Before calling a function, the arguments are pushed onto the stack in right-to-left order (according to most calling conventions). This means the first argument (from the perspective of the function) is stored at the lowest memory address.
2. Execute the call Instruction:
When the call instruction is executed, the CPU performs two key actions:
Push Return Address onto the Stack: The CPU pushes the current value of the EIP (Instruction Pointer), which points to the next instruction after the call, onto the stack. This is the return address, and it tells the function where to go after it completes execution.
Jump to the Function's Address: The CPU sets the EIP to the address of the function being called, effectively transferring control to the function's code.
3. Adjust the Stack Pointer (ESP) Inside the Function:
Inside the function, the ESP (Stack Pointer) might be adjusted (incremented or decremented) to make room for local variables or to save registers. This is part of setting up the function's stack frame.
4. Execute the Function's Code:
The function runs its code, making use of the arguments stored on the stack, manipulating local variables, and potentially calling other functions.
5. Return from the Function:
When the function completes execution, the ret (return) instruction is used to return control to the calling function.
Pop the Return Address: The ret instruction pops the return address off the stack and places it back into the EIP register.
Jump Back to the Caller: The CPU jumps to the address stored in the EIP, which is the instruction immediately following the original call.
6. Continue Execution:
The program resumes execution at the instruction following the call, as though the function had just been another line of code.
Visualization of Stack Operations:
Before the function call:

javascript
Copy code
Stack (from high to low addresses):
[Function arguments]
After the call instruction:

vbnet
Copy code
Stack (from high to low addresses):
[Return Address] <- EIP points to this after pushing it to the stack
[Function arguments]
During function execution:

csharp
Copy code
Stack (from high to low addresses):
[Local variables, saved registers, etc.]
[Return Address]
[Function arguments]
After returning from the function:

The stack pointer is restored, the return address is popped, and execution continues after the call.
Summary:
Pushing Arguments: Function arguments are pushed onto the stack in right-to-left order.
Saving the Return Address: The call instruction saves the return address (the next instruction after the call) on the stack, allowing the program to return to the correct location after function execution.
Executing the Function: The CPU jumps to the function's code and adjusts the stack as needed.
Returning Control: The ret instruction pops the return address from the stack, restoring control to the point in the code where the function was originally called.
This process ensures that the program can manage function calls and returns seamlessly while maintaining the correct flow of execution.
------------------------------------
so when we say saving the old stack frame this means saving its ebp address in the stack like we did when we wanted to save the next instruction to be executed after the funtion execution by saving the EIP , and when we say creating new stack frame this means we will adjust the base pointer and stack pointer to take a portion of the stack to execute our function
-------------------------------------------





EFLAGS Register (32-bit):

The EFLAGS register is a 32-bit register in the x86 architecture that holds various flags. Each bit in this register serves a specific purpose, representing different status, control, or system flags.
Key Flags in the EFLAGS Register:

CF (Carry Flag, bit 0): Indicates whether a carry or borrow occurred in arithmetic operations.
PF (Parity Flag, bit 2): Indicates whether the number of set bits in the result is even or odd.
AF (Auxiliary Carry Flag, bit 4): Used for binary-coded decimal (BCD) arithmetic; indicates a carry out of the lower nibble.
ZF (Zero Flag, bit 6): Set if the result of an operation is zero.
SF (Sign Flag, bit 7): Set if the result of an operation is negative (sign bit is set).
OF (Overflow Flag, bit 11): Set if an arithmetic operation causes a signed overflow.
DF (Direction Flag, bit 10): Controls the direction for string operations.
IF (Interrupt Flag, bit 9): Controls the enabling/disabling of interrupts.
TF (Trap Flag, bit 8): Enables single-step debugging.
How Flags Are Modified:

When an instruction like ADD, SUB, CMP, or AND is executed, certain flags in the EFLAGS register are modified based on the result of that operation.
For example, if the result of an ADD instruction is zero, the ZF (Zero Flag) will be set to 1.
Similarly, if an overflow occurs during the addition of two signed numbers, the OF (Overflow Flag) will be set to 1.
Flags Can Be Read and Used in Conditional Jumps:

After an instruction modifies the flags, those flags can be used by other instructions. For example, conditional jump instructions like JZ (Jump if Zero) or JC (Jump if Carry) will check the corresponding flag in the EFLAGS register to decide whether to jump or not.
Single EFLAGS Register:

There is only one EFLAGS register in the CPU, so it is shared among all instructions. When a new instruction is executed, it may modify some or all of the flags in the EFLAGS register.
Example:
assembly

add eax, ebx  ; Perform addition, modify flags like ZF, SF, OF, etc.
jnz label     ; Jump to "label" if the Zero Flag (ZF) is not set (result was not zero)
In this example:

The add instruction may modify several flags in the EFLAGS register.
The jnz instruction checks the Zero Flag (ZF) in the EFLAGS register to determine whether to jump to the specified label or not.




--------------------------------------
EAX – The Accumulator Register. 

It’s called the accumulator register because it’s the primary register used for common calculations (such as ADD and SUB).  While other registers can be used for calculations, EAX has been given preferential status by assigning it more efficient, one-byte opcodes.  Such efficiency can be important when it comes to writing exploit shellcode for a limited available buffer space (more on that in future tutorials!).  In addition to its use in calculations, EAX is also used to store the return value of a function. 

This general purpose register can be referenced in whole or in part as follows: EAX refers to the 32-bit register in its entirety. AX refers to the least significant 16 bits which can be further broken down into AH (the 8 most significant bits of AX) and AL (the 8 least significant bits).

EBX – The Base Register. 

In 32-bit architecture, EBX doesn’t really have a special purpose so just think of it as a catch-all for available storage.  Like EAX, it can be referenced in whole (EBX) or in part (BX, BH, BL).

ECX – The Counter Register. 

As its name implies, the counter (or count) register is frequently used as a loop and function repetition counter, though it can also be used to store any data.  Like EAX, it can be referenced in whole (ECX) or in part (CX, CH, CL).

EDX – The Data Register

EDX is kind of like a partner register to EAX. It’s often used in mathematical operations like division and multiplication to deal with overflow where the most significant bits would be stored in EDX and the least significant in EAX.  It is also commonly used for storing function variables.  Like EAX, it can be referenced in whole (EDX) or in part (DX, DH, DL).

ESI – The Source Index

The counterpart to EDI, ESI is often used to store the pointer to a read location.  For example, if a function is designed to read a string, ESI would hold the pointer to the location of that string.

EDI – The Destination Index

Though it can be (and is) used for general data storage, EDI was primarily designed to store the storage pointers of functions, such as the write address of a string operation.

EBP – The Base Pointer

EBP is used to keep track of the base/bottom of the stack.  It is often used to reference variables located on the stack by using an offset to the current value of EBP, though if parameters are only referenced by register, you may choose to use EBP for general use purposes.  

ESP – The Stack Pointer

ESP is used to track the top of the stack. As items are moved to and from the stack ESP increments/decrements accordingly.  Of all of the general purpose registers, ESP is rarely/never used for anything other than it’s intended purpose. 

The Instruction Pointer (EIP)

Not a general purpose register, but fitting to cover here, EIP points to the memory address of the next instruction to be executed by the CPU.  As you’ll see in the coming tutorials, control the value of EIP and you can control the execution flow of the application (to execute code of your choosing).  

-----------------------
The EDX register can be used in conjunction with overflow handling primarily in the context of multiplication and division operations in assembly language, specifically in scenarios where the result of an operation exceeds the size of a single register (like the EAX register). Here’s how EDX plays a role in handling overflow during these operations:

1. Multiplication (MUL/IMUL):
When performing multiplication of two 32-bit numbers, the result may be larger than 32 bits (up to 64 bits). In such cases, the product is stored across two registers: EAX and EDX.
The lower 32 bits of the result are stored in EAX, and the upper 32 bits are stored in EDX.
If EDX contains any non-zero value after the multiplication, this indicates that the result has overflowed the 32-bit size of EAX.
Example with MUL:
assembly

mov eax, 0xFFFFFFFF  ; Load a large value into EAX
mov ebx, 2           ; Load 2 into EBX
mul ebx              ; Multiply EAX by EBX (EAX = EAX * EBX)

; Now the result of the multiplication is stored in EDX:EAX.
; EDX will contain the upper 32 bits of the 64-bit result.
; If EDX is non-zero, it indicates overflow.
In this example, multiplying 0xFFFFFFFF (the maximum 32-bit value) by 2 results in a value larger than 32 bits, so EDX will hold the overflow portion of the result.
2. Division (DIV/IDIV):
In division, the EDX register is often used to hold the remainder of a division operation when dividing 64-bit numbers.
Before performing a 32-bit division, EDX must be cleared or set appropriately, as the dividend is considered a 64-bit value composed of EDX
(with EDX holding the high 32 bits and EAX holding the low 32 bits).
If EDX contains a non-zero value that cannot be divided by the divisor in DIV/IDIV, an overflow or divide error occurs.
Example with DIV:
assembly

mov edx, 0           ; Clear EDX for 32-bit division
mov eax, 1000000000  ; Load a large dividend into EAX
mov ecx, 10          ; Load the divisor into ECX
div ecx              ; Perform division (EAX = EDX:EAX / ECX)

; The quotient is stored in EAX, and the remainder is stored in EDX.
; If EDX is non-zero before the division, it can indicate potential overflow.
In this case, EDX is cleared before the division to prevent overflow. The quotient is stored in EAX, and the remainder is stored in EDX.
3. Overflow Flag (OF) and EDX:
While EDX handles the overflow of the data from a multiplication or division, the Overflow Flag (OF) in the EFLAGS register signals whether an arithmetic overflow occurred during operations like addition or subtraction.
EDX does not directly affect the OF flag, but its contents (especially in multiplication) indicate when a result has overflowed beyond the capacity of EAX.
-------------------------------
EDX is used in operations that can produce results larger than what can be stored in a single 32-bit register.
In multiplication, EDX holds the upper 32 bits of the result, indicating overflow if non-zero.
In division, EDX is part of the dividend and holds the remainder after division.
EDX doesn't directly set the OF flag, but its role in operations can signal when overflow occurs that requires handling beyond what EAX can store.
---------------------------------
What are Segment Registers?
In x86 architecture, segment registers are used to store the base addresses of memory segments. They help the CPU determine where in memory it should read or write data. Each segment register holds a 16-bit value that points to the start of a segment in memory.

Segment registers are a specific type of register used in x86 architecture to manage memory segmentation. Memory segmentation is a technique used to divide a computer's memory into different segments, which allows the CPU to access larger amounts of memory than it could with a flat memory model.
The Primary Segment Registers:


1.CS (Code Segment):

Points to the segment containing the current code (instructions being executed).
The CPU fetches instructions from this segment.



2.DS (Data Segment):

Points to the segment containing global or static data used by programs.
The CPU accesses data from this segment when performing data operations.


3.SS (Stack Segment):

Points to the segment containing the stack, which is used for function calls, local variables, and return addresses.
The stack operations (push, pop) reference this segment.


4.ES (Extra Segment):

An additional data segment, often used for string operations or accessing additional data.
Used in conjunction with other segment registers for more complex data handling.



5.FS and GS:

Additional segment registers introduced in later x86 architectures.
Often used for accessing thread-local storage or other special-purpose data in modern operating systems.

------------------------------------------
Big-Endian:
Big-endian systems store the most significant byte (MSB) of a multi-byte value at the lowest (starting) memory address.
This means that the most significant byte is stored first, at the lowest memory address, and the least significant byte (LSB) is stored at the highest memory address.
Example:
Consider storing the 4-byte (32-bit) integer 0x12345678 in big-endian format:

Address	Value
0x1000	0x12
0x1001	0x34
0x1002	0x56
0x1003	0x78
Here, the most significant byte (0x12) is stored at the lowest memory address (0x1000), and the least significant byte (0x78) is stored at the highest memory address (0x1003).

Little-Endian:
Little-endian systems store the least significant byte (LSB) of a multi-byte value at the lowest (starting) memory address.
This means that the least significant byte is stored first, at the lowest memory address, and the most significant byte (MSB) is stored at the highest memory address.
Example:
Consider storing the same 4-byte (32-bit) integer 0x12345678 in little-endian format:

Address	Value
0x1000	0x78
0x1001	0x56
0x1002	0x34
0x1003	0x12
Here, the least significant byte (0x78) is stored at the lowest memory address (0x1000), and the most significant byte (0x12) is stored at the highest memory address (0x1003).

Summary:
In big-endian, the MSB is stored at the lowest memory address, so the values are represented in memory exactly as they appear in the number (left to right).
In little-endian, the LSB is stored at the lowest memory address, so the values are stored in reverse order (right to left).
The choice of endianness affects how data is interpreted when read from memory, but it doesn't change the actual value of the data; it only changes how it's stored.
-------------------------------------------------------------------------------------------
big endianness the MSB stored at the lowest memory address which means that it is stored at the top of the stack visually and is like if we pushed values to stack we start from right so as it is the last item in the stack we can consider it is on the left 
---------------------------------------------
THE LAST TOPIC HERE IS NOPS :::::::
------------------------------------
NOPs (No Operation instructions) are crucial in the context of buffer overflow exploits, particularly for aligning your shellcode (or payload) with the targeted buffer's expected size and location. Here's a breakdown of how NOPs work and why they are useful in buffer overflow scenarios:

What is a NOP?
NOP (No Operation) is an assembly instruction that tells the CPU to do nothing for one clock cycle. It doesn't alter the processor state or memory but simply advances the instruction pointer (EIP/RIP) to the next instruction.
In x86 architecture, the NOP instruction is typically represented by the opcode 0x90.
Why are NOPs Useful in Buffer Overflow Exploits?
Creating a NOP Sled:

A NOP sled is a series of consecutive NOP instructions (e.g., 0x90 0x90 0x90...) placed before your shellcode in a buffer.
When exploiting a buffer overflow, you may not know the exact address where the instruction pointer (EIP/RIP) will land. By placing a NOP sled before your payload, you create a "safe zone."
If the instruction pointer lands anywhere within the NOP sled, it will "slide" down the NOPs until it reaches your shellcode, ensuring that your code gets executed.
Handling Inaccurate Offsets:

Sometimes, it's challenging to calculate the precise memory address where your shellcode will reside after overflowing the buffer.
The NOP sled helps absorb this inaccuracy. Even if your EIP/RIP doesn't point directly at the start of your shellcode, the sled will lead it there.
Matching Program Expected Size:

Programs may expect input buffers of a specific size. To match this expected size and still ensure that your payload is executed, you can fill any unused space in the buffer with NOPs.
This ensures that your exploit doesn't cause unintended behavior (like crashes) before your payload is executed, by neatly aligning with the program’s memory layout expectations.
Making Exploits More Reliable:

Buffer overflow exploits can be sensitive to minor variations in the environment (e.g., different operating system versions, stack layout). NOP sleds increase the reliability of an exploit by allowing some flexibility in where the instruction pointer lands.
Example of a Buffer Overflow Exploit with a NOP Sled:
Let's say you're exploiting a buffer overflow vulnerability, and you want to inject shellcode into a vulnerable program. Here’s a simplified example:

Identify the Vulnerability:

You find that a program has a buffer overflow vulnerability, allowing you to overwrite the return address.
Create the Payload:

The payload consists of three parts:
NOP Sled: A series of NOP instructions (e.g., 100 bytes of 0x90).
Shellcode: The actual malicious code you want to execute (e.g., 50 bytes of shellcode).
Return Address Overwrite: The address where you want the program to return after the overflow. Ideally, this address should point somewhere in the middle of the NOP sled.
Exploit Execution:

When the program is exploited, the stack gets overflowed with your payload. Even if the return address doesn't point exactly at the start of your shellcode, the NOP sled will "catch" the instruction pointer and guide it to the shellcode.
Visualization:
Original Stack Layout:
[ Buffer ][ Return Address ]
Overflowed Stack Layout with NOP Sled:
[ NOP Sled ][ Shellcode ][ Overwritten Return Address ]
The return address is overwritten with a pointer to somewhere in the NOP sled. When the function returns, it lands in the NOP sled, slides through the NOPs, and eventually reaches and executes your shellcode.

Key Points to Remember:
NOP sleds provide flexibility in where the program can land when you’re unsure of the exact memory address.
They help ensure that your payload is executed even if your calculation of the return address is slightly off.
Buffer alignment using NOPs allows you to pad your payload to fit the buffer size that the program expects.
By using NOPs effectively, you increase the chances of your buffer overflow exploit succeeding, making them a crucial tool in crafting reliable exploits.
